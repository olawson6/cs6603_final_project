{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f55da84",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db197f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915d4a9b",
   "metadata": {},
   "source": [
    "# Step 1 DataSet Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ee3eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"state_GA.csv\" \n",
    "data = pd.read_csv(file)\n",
    "\n",
    "data_reduced = data[['lei', 'derived_ethnicity', 'derived_race', 'derived_sex', 'loan_amount', 'debt_to_income_ratio', 'loan_purpose', 'loan_term', 'action_taken', 'denial_reason-1', 'denial_reason-2', \n",
    "                     'income', 'applicant_age', 'total_loan_costs', 'interest_rate', 'applicant_race-1', 'applicant_race-2', 'applicant_sex','co-applicant_sex']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5588ca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Only Need to run once\n",
    "data_reduced.to_csv(\"state_GA_reduced.csv\", index=False)\n",
    "hmda_data = pd.read_csv(\"state_GA_reduced.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55afda23",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_map = {\n",
    "    1: \"Male\",\n",
    "    2: \"Female\",\n",
    "    6: \"Applicant selected both male and female\"\n",
    "}\n",
    "\n",
    "race_map = {\n",
    "    1: \"American Indian or Alaska Native\",\n",
    "    2: \"Asian\",\n",
    "    21: \"Asian Indian\",\n",
    "    22: \"Chinese\",\n",
    "    23: \"Filipino\",\n",
    "    24: \"Japanese\",\n",
    "    25: \"Korean\",\n",
    "    26: \"Vietnamese\",\n",
    "    27: \"Other Asian\",\n",
    "    3: \"Black or African American\",\n",
    "    4: \"Native Hawaiian or Other Pacific Islander\",\n",
    "    41: \"Native Hawaiian\",\n",
    "    42: \"Guamanian or Chamorro\",\n",
    "    43: \"Samoan\",\n",
    "    44: \"Other Pacific Islander\",\n",
    "    5: \"White\"\n",
    "}\n",
    "\n",
    "data_reduced['applicant_race-1'] = pd.to_numeric(data_reduced['applicant_race-1'], errors='coerce')\n",
    "data_reduced['applicant_race-2'] = pd.to_numeric(data_reduced['applicant_race-2'], errors='coerce')\n",
    "data_reduced['applicant_sex'] = pd.to_numeric(data_reduced['applicant_sex'], errors='coerce')\n",
    "data_reduced['co-applicant_sex'] = pd.to_numeric(data_reduced['co-applicant_sex'], errors='coerce')\n",
    "\n",
    "filtered = data_reduced[\n",
    "    data_reduced['applicant_race-1'].isin(race_map.keys()) &\n",
    "    (\n",
    "        data_reduced['applicant_race-2'].isna() |\n",
    "        data_reduced['applicant_race-2'].isin(race_map.keys())\n",
    "    ) &\n",
    "    data_reduced['applicant_sex'].isin(sex_map.keys()) &\n",
    "    (\n",
    "        data_reduced['co-applicant_sex'].isna() |\n",
    "        data_reduced['co-applicant_sex'].isin(sex_map.keys())\n",
    "    )\n",
    "\n",
    "]\n",
    "\n",
    "filtered['race_1_str'] = filtered['applicant_race-1'].map(race_map)\n",
    "filtered['race_2_str'] = filtered['applicant_race-2'].map(race_map)\n",
    "def combine_races_str(row):\n",
    "    if pd.isna(row['race_2_str']) or row['race_2_str'] == \"\":\n",
    "        return row['race_1_str']\n",
    "    return f\"{row['race_1_str']}, {row['race_2_str']}\"\n",
    "def combine_sexs_str(row):\n",
    "    if pd.isna(row['co-applicant_sex']) or row['co-applicant_sex'] == \"\":\n",
    "        return row['applicant_sex']\n",
    "    return f\"{row['applicant_sex']}, {row['co-applicant_sex']}\"\n",
    "\n",
    "filtered['derived_race_new'] = filtered.apply(combine_races_str, axis=1)\n",
    "\n",
    "filtered['applicant_sex'] = filtered['applicant_sex'].map(sex_map)\n",
    "filtered['co-applicant_sex'] = filtered['co-applicant_sex'].map(sex_map)\n",
    "\n",
    "filtered['derived_sex_new'] = filtered.apply(combine_sexs_str, axis=1)\n",
    "\n",
    "filtered = filtered[filtered['action_taken'] != 6]\n",
    "filtered = filtered[filtered['interest_rate'] != 'Exempt']\n",
    "\n",
    "\n",
    "filtered['favorable_action_taken'] = filtered['action_taken'].apply(\n",
    "    lambda x: 1 if x in [1, 2, 8] else (0 if x in [3, 4, 5, 7] else pd.NA)\n",
    ")\n",
    "filtered['interest_rate'].unique()\n",
    "filtered['favorable_interest_rate'] = filtered['interest_rate'].apply(\n",
    "    lambda x: 1 if float(x) <= 7.5 else 0)\n",
    "\n",
    "unique_races = sorted(filtered['derived_race_new'].unique())\n",
    "unique_sexes = sorted(filtered['derived_sex_new'].unique())\n",
    "\n",
    "# New encoding dictionaries\n",
    "final_race_encoding = {race: i for i, race in enumerate(unique_races)}\n",
    "final_sex_encoding = {sex: i for i, sex in enumerate(unique_sexes)}\n",
    "\n",
    "filtered['derived_race_encoded'] = filtered['derived_race_new'].map(final_race_encoding)\n",
    "filtered['derived_sex_encoded'] = filtered['derived_sex_new'].map(final_sex_encoding)\n",
    "\n",
    "\n",
    "filtered.to_csv(\"state_GA_reduced_encoded.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0d10c1",
   "metadata": {},
   "source": [
    "# Analysis for Steps 3 and 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00928235",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0972034c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv('state_GA_reduced_encoded.csv')\n",
    "    print(\"Dataset loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'state_GA_reduced_encoded.csv' not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f27963b",
   "metadata": {},
   "source": [
    "## Data Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03a5f080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Initial Data Summary ---\n",
      "Original dataset shape: (109250, 26)\n",
      "\n",
      "Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 109250 entries, 0 to 109249\n",
      "Data columns (total 26 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   lei                   109250 non-null  object \n",
      " 1   derived_ethnicity     109250 non-null  object \n",
      " 2   derived_race          109250 non-null  object \n",
      " 3   derived_sex           109250 non-null  object \n",
      " 4   loan_amount           109250 non-null  float64\n",
      " 5   debt_to_income_ratio  84112 non-null   object \n",
      " 6   loan_purpose          109250 non-null  int64  \n",
      " 7   loan_term             108220 non-null  object \n",
      " 8   action_taken          109250 non-null  int64  \n",
      " 9   denial_reason-1       109250 non-null  int64  \n",
      " 10  denial_reason-2       3930 non-null    float64\n",
      " 11  income                104831 non-null  float64\n",
      " 12  applicant_age         109250 non-null  object \n",
      " 13  total_loan_costs      54646 non-null   object \n",
      " 14  interest_rate         69954 non-null   object \n",
      " 15  applicant_race-1      109250 non-null  float64\n",
      " 16  applicant_race-2      6721 non-null    float64\n",
      " 17  applicant_sex         109250 non-null  object \n",
      " 18  co-applicant_sex      109250 non-null  object \n",
      " 19  race_1_str            109250 non-null  object \n",
      " 20  race_2_str            6721 non-null    object \n",
      " 21  derived_race_new      109250 non-null  object \n",
      " 22  derived_sex_new       109250 non-null  object \n",
      " 23  derived_action_taken  109250 non-null  int64  \n",
      " 24  derived_race_encoded  109250 non-null  int64  \n",
      " 25  derived_sex_encoded   109250 non-null  int64  \n",
      "dtypes: float64(5), int64(6), object(15)\n",
      "memory usage: 21.7+ MB\n",
      "\n",
      "Value Counts for Action Taken:\n",
      "1    66911\n",
      "3    17876\n",
      "4    15723\n",
      "5     5695\n",
      "2     2842\n",
      "8      144\n",
      "7       59\n",
      "Name: action_taken, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Initial Data Summary ---\")\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "print(\"\\nData Info:\")\n",
    "df.info()\n",
    "print(\"\\nValue Counts for Action Taken:\")\n",
    "print(df['action_taken'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c92e09f",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "037c6671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependent variables prepared.\n",
      "\n",
      "Dropped 4419 rows with missing values in feature columns to prepare for modeling.\n",
      "Shape of data ready for modeling: (104831, 27)\n",
      "\n",
      "--- Protected Class Subgroup Counts ---\n",
      "\n",
      "Sex Analysis Subgroups (sex_df):\n",
      "Male      68120\n",
      "Female    36442\n",
      "Name: applicant_sex, dtype: int64\n",
      "\n",
      "Race Analysis Subgroups (race_df):\n",
      "White                        75422\n",
      "Black or African American    19982\n",
      "Name: derived_race_new, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['interest_rate'] = pd.to_numeric(df['interest_rate'], errors='coerce')\n",
    "df['favorable_interest_rate'] = np.where(df['interest_rate'] < 7.5, 1, 0)\n",
    "print(\"\\nDependent variables prepared.\")\n",
    "\n",
    "FEATURES = ['loan_amount', 'income', 'derived_race_encoded', 'derived_sex_encoded']\n",
    "\n",
    "df['income'] = pd.to_numeric(df['income'], errors='coerce')\n",
    "original_rows = len(df)\n",
    "df.dropna(subset=FEATURES, inplace=True)\n",
    "print(f\"\\nDropped {original_rows - len(df)} rows with missing values in feature columns to prepare for modeling.\")\n",
    "print(f\"Shape of data ready for modeling: {df.shape}\")\n",
    "\n",
    "\n",
    "sex_df = df[df['applicant_sex'].isin(['Male', 'Female'])].copy()\n",
    "race_df = df[df['derived_race_new'].isin(['White', 'Black or African American'])].copy()\n",
    "privileged_sex_group = {'applicant_sex': 'Male'}\n",
    "unprivileged_sex_group = {'applicant_sex': 'Female'}\n",
    "privileged_race_group = {'derived_race_new': 'White'}\n",
    "unprivileged_race_group = {'derived_race_new': 'Black or African American'}\n",
    "print(\"\\n--- Protected Class Subgroup Counts ---\")\n",
    "print(\"\\nSex Analysis Subgroups (sex_df):\")\n",
    "print(sex_df['applicant_sex'].value_counts())\n",
    "print(\"\\nRace Analysis Subgroups (race_df):\")\n",
    "print(race_df['derived_race_new'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91dc0f0",
   "metadata": {},
   "source": [
    "# Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd225c3c",
   "metadata": {},
   "source": [
    "### Manual Fairness Metric Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a37c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual computation of fairness metrics\n",
    "def compute_manual_fairness_metrics(df, protected_attribute, dependent_variable, privileged_group, unprivileged_group, weights_col=None):\n",
    "    priv_key, priv_val = list(privileged_group.items())[0]\n",
    "    unpriv_key, unpriv_val = list(unprivileged_group.items())[0]\n",
    "    df_priv = df[df[priv_key] == priv_val]\n",
    "    df_unpriv = df[df[unpriv_key] == unpriv_val]\n",
    "    \n",
    "    if weights_col and not df_priv.empty and not df_unpriv.empty:\n",
    "        rate_priv = (df_priv[dependent_variable] * df_priv[weights_col]).sum() / df_priv[weights_col].sum()\n",
    "        rate_unpriv = (df_unpriv[dependent_variable] * df_unpriv[weights_col]).sum() / df_unpriv[weights_col].sum()\n",
    "    elif not df_priv.empty and not df_unpriv.empty:\n",
    "        rate_priv = df_priv[dependent_variable].mean()\n",
    "        rate_unpriv = df_unpriv[dependent_variable].mean()\n",
    "    else:\n",
    "        return {'Statistical Parity Difference': np.nan, 'Disparate Impact': np.nan}\n",
    "        \n",
    "    spd = rate_unpriv - rate_priv\n",
    "    di = rate_unpriv / (rate_priv + 1e-7)\n",
    "    return {'Statistical Parity Difference': spd, 'Disparate Impact': di}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250df596",
   "metadata": {},
   "source": [
    "### Apply Reweighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453fd575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual application of reweighting\n",
    "def apply_reweighting(df, protected_attribute, dependent_variable, privileged_group, unprivileged_group):\n",
    "    df_new = df.copy()\n",
    "    priv_key, priv_val = list(privileged_group.items())[0]\n",
    "    unpriv_key, unpriv_val = list(unprivileged_group.items())[0]\n",
    "    priv_fav = (df_new[priv_key] == priv_val) & (df_new[dependent_variable] == 1)\n",
    "    priv_unfav = (df_new[priv_key] == priv_val) & (df_new[dependent_variable] == 0)\n",
    "    unpriv_fav = (df_new[unpriv_key] == unpriv_val) & (df_new[dependent_variable] == 1)\n",
    "    unpriv_unfav = (df_new[unpriv_key] == unpriv_val) & (df_new[dependent_variable] == 0)\n",
    "    N = len(df_new)\n",
    "    p_priv = (df_new[priv_key] == priv_val).sum() / N\n",
    "    p_unpriv = (df_new[unpriv_key] == unpriv_val).sum() / N\n",
    "    p_fav = (df_new[dependent_variable] == 1).sum() / N\n",
    "    p_unfav = (df_new[dependent_variable] == 0).sum() / N\n",
    "    p_priv_fav = priv_fav.sum() / N; p_priv_unfav = priv_unfav.sum() / N\n",
    "    p_unpriv_fav = unpriv_fav.sum() / N; p_unpriv_unfav = unpriv_unfav.sum() / N\n",
    "    w_priv_fav = (p_priv * p_fav) / p_priv_fav if p_priv_fav > 0 else 1.0\n",
    "    w_priv_unfav = (p_priv * p_unfav) / p_priv_unfav if p_priv_unfav > 0 else 1.0\n",
    "    w_unpriv_fav = (p_unpriv * p_fav) / p_unpriv_fav if p_unpriv_fav > 0 else 1.0\n",
    "    w_unpriv_unfav = (p_unpriv * p_unfav) / p_unpriv_unfav if p_unpriv_unfav > 0 else 1.0\n",
    "    df_new['sample_weight'] = 1.0\n",
    "    df_new.loc[priv_fav, 'sample_weight'] = w_priv_fav\n",
    "    df_new.loc[priv_unfav, 'sample_weight'] = w_priv_unfav\n",
    "    df_new.loc[unpriv_fav, 'sample_weight'] = w_unpriv_fav\n",
    "    df_new.loc[unpriv_unfav, 'sample_weight'] = w_unpriv_unfav\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fafbafc",
   "metadata": {},
   "source": [
    "## Preprocess and Mitigate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d300f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Statistical Parity Difference  \\\n",
      "Sex vs. Action Taken                                   0.082922   \n",
      "Race vs. Action Taken                                  0.367557   \n",
      "Sex vs. Favorable Interest Rate                       -0.004527   \n",
      "Race vs. Favorable Interest Rate                      -0.073302   \n",
      "\n",
      "                                  Disparate Impact  \n",
      "Sex vs. Action Taken                      1.042136  \n",
      "Race vs. Action Taken                     1.191670  \n",
      "Sex vs. Favorable Interest Rate           0.989941  \n",
      "Race vs. Favorable Interest Rate          0.839495  \n"
     ]
    }
   ],
   "source": [
    "original_metrics = {\n",
    "    'Sex vs. Action Taken': compute_manual_fairness_metrics(sex_df, 'applicant_sex', 'action_taken', privileged_sex_group, unprivileged_sex_group),\n",
    "    'Race vs. Action Taken': compute_manual_fairness_metrics(race_df, 'derived_race_new', 'action_taken', privileged_race_group, unprivileged_race_group),\n",
    "    'Sex vs. Favorable Interest Rate': compute_manual_fairness_metrics(sex_df, 'applicant_sex', 'favorable_interest_rate', privileged_sex_group, unprivileged_sex_group),\n",
    "    'Race vs. Favorable Interest Rate': compute_manual_fairness_metrics(race_df, 'derived_race_new', 'favorable_interest_rate', privileged_race_group, unprivileged_race_group)\n",
    "}\n",
    "print(pd.DataFrame.from_dict(original_metrics, orient='index'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063234ad",
   "metadata": {},
   "source": [
    "### Reweight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00aa0895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reweighting applied to create transformed datasets.\n"
     ]
    }
   ],
   "source": [
    "sex_df_transformed = apply_reweighting(sex_df, 'applicant_sex', 'action_taken', privileged_sex_group, unprivileged_sex_group)\n",
    "race_df_transformed = apply_reweighting(race_df, 'derived_race_new', 'action_taken', privileged_race_group, unprivileged_race_group)\n",
    "print(\"\\nReweighting applied to create transformed datasets.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68cafb7",
   "metadata": {},
   "source": [
    "### Transformed Data Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dce6794f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Statistical Parity Difference  \\\n",
      "Sex vs. Action Taken                                   0.048991   \n",
      "Race vs. Action Taken                                  0.201853   \n",
      "Sex vs. Favorable Interest Rate                        0.004373   \n",
      "Race vs. Favorable Interest Rate                      -0.028255   \n",
      "\n",
      "                                  Disparate Impact  \n",
      "Sex vs. Action Taken                      1.024750  \n",
      "Race vs. Action Taken                     1.103655  \n",
      "Sex vs. Favorable Interest Rate           1.009780  \n",
      "Race vs. Favorable Interest Rate          0.937112  \n"
     ]
    }
   ],
   "source": [
    "transformed_metrics = {\n",
    "    'Sex vs. Action Taken': compute_manual_fairness_metrics(sex_df_transformed, 'applicant_sex', 'action_taken', privileged_sex_group, unprivileged_sex_group, weights_col='sample_weight'),\n",
    "    'Race vs. Action Taken': compute_manual_fairness_metrics(race_df_transformed, 'derived_race_new', 'action_taken', privileged_race_group, unprivileged_race_group, weights_col='sample_weight'),\n",
    "    'Sex vs. Favorable Interest Rate': compute_manual_fairness_metrics(sex_df_transformed, 'applicant_sex', 'favorable_interest_rate', privileged_sex_group, unprivileged_sex_group, weights_col='sample_weight'),\n",
    "    'Race vs. Favorable Interest Rate': compute_manual_fairness_metrics(race_df_transformed, 'derived_race_new', 'favorable_interest_rate', privileged_race_group, unprivileged_race_group, weights_col='sample_weight')\n",
    "}\n",
    "print(pd.DataFrame.from_dict(transformed_metrics, orient='index'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541e1c78",
   "metadata": {},
   "source": [
    "# Step 4 Mitigating Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f897f61",
   "metadata": {},
   "source": [
    "### Data Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ced5967",
   "metadata": {},
   "source": [
    "#### Sex Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07a4e058",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sex = sex_df[FEATURES]\n",
    "y_sex = sex_df['action_taken']\n",
    "X_sex_train, X_sex_test, y_sex_train, y_sex_test = train_test_split(X_sex, y_sex, test_size=0.2, random_state=42, stratify=y_sex)\n",
    "X_sex_transformed = sex_df_transformed[FEATURES]\n",
    "y_sex_transformed = sex_df_transformed['action_taken']\n",
    "weights_sex_transformed = sex_df_transformed['sample_weight']\n",
    "X_sex_train_t, X_sex_test_t, y_sex_train_t, y_sex_test_t, w_sex_train_t, w_sex_test_t = train_test_split(\n",
    "X_sex_transformed, y_sex_transformed, weights_sex_transformed, test_size=0.2, random_state=42, stratify=y_sex_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baea033d",
   "metadata": {},
   "source": [
    "#### Race Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb8002d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_race = race_df[FEATURES]\n",
    "y_race = race_df['action_taken']\n",
    "X_race_train, X_race_test, y_race_train, y_race_test = train_test_split(X_race, y_race, test_size=0.2, random_state=42, stratify=y_race)\n",
    "X_race_transformed = race_df_transformed[FEATURES]\n",
    "y_race_transformed = race_df_transformed['action_taken']\n",
    "weights_race_transformed = race_df_transformed['sample_weight']\n",
    "X_race_train_t, X_race_test_t, y_race_train_t, y_race_test_t, w_race_train_t, w_race_test_t = train_test_split(\n",
    "X_race_transformed, y_race_transformed, weights_race_transformed, test_size=0.2, random_state=42, stratify=y_race_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c7eb63",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c26d37a",
   "metadata": {},
   "source": [
    "#### Original Data Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c48541e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of original model (Sex): 0.23\n",
      "Accuracy of original model (Race): 0.23\n",
      "Accuracy of transformed model (Sex): 0.62\n",
      "Accuracy of transformed model (Race): 0.62\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "model_sex_original = LogisticRegression(random_state=42, class_weight='balanced')\n",
    "model_sex_original.fit(scaler.fit_transform(X_sex_train), y_sex_train)\n",
    "sex_test_preds_original = model_sex_original.predict(scaler.transform(X_sex_test))\n",
    "print(f\"Accuracy of original model (Sex): {accuracy_score(y_sex_test, sex_test_preds_original):.2f}\")\n",
    "\n",
    "model_race_original = LogisticRegression(random_state=42, class_weight='balanced')\n",
    "model_race_original.fit(scaler.fit_transform(X_race_train), y_race_train)\n",
    "race_test_preds_original = model_race_original.predict(scaler.transform(X_race_test))\n",
    "print(f\"Accuracy of original model (Race): {accuracy_score(y_race_test, race_test_preds_original):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f01a20b",
   "metadata": {},
   "source": [
    "#### Transformed Data Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858a2ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sex_transformed = LogisticRegression(random_state=42)\n",
    "model_sex_transformed.fit(scaler.fit_transform(X_sex_train_t), y_sex_train_t, sample_weight=w_sex_train_t)\n",
    "sex_test_preds_transformed = model_sex_transformed.predict(scaler.transform(X_sex_test_t))\n",
    "print(f\"Accuracy of transformed model (Sex): {accuracy_score(y_sex_test_t, sex_test_preds_transformed):.2f}\")\n",
    "\n",
    "\n",
    "model_race_transformed = LogisticRegression(random_state=42)\n",
    "model_race_transformed.fit(scaler.fit_transform(X_race_train_t), y_race_train_t, sample_weight=w_race_train_t)\n",
    "race_test_preds_transformed = model_race_transformed.predict(scaler.transform(X_race_test_t))\n",
    "print(f\"Accuracy of transformed model (Race): {accuracy_score(y_race_test_t, race_test_preds_transformed):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2511cada",
   "metadata": {},
   "source": [
    "## Fairness Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41b38c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Statistical Parity Difference  Disparate Impact\n",
      "Sex vs. Prediction                        1.178995          1.287554\n",
      "Race vs. Prediction                       0.545521          1.126932\n",
      "                     Statistical Parity Difference  Disparate Impact\n",
      "Sex vs. Prediction                        0.000119          1.000118\n",
      "Race vs. Prediction                       0.000311          1.000311\n"
     ]
    }
   ],
   "source": [
    "sex_test_df_original = sex_df.loc[X_sex_test.index].copy()\n",
    "sex_test_df_original['prediction'] = sex_test_preds_original\n",
    "race_test_df_original = race_df.loc[X_race_test.index].copy()\n",
    "race_test_df_original['prediction'] = race_test_preds_original\n",
    "sex_test_df_transformed = sex_df_transformed.loc[X_sex_test_t.index].copy()\n",
    "sex_test_df_transformed['prediction'] = sex_test_preds_transformed\n",
    "race_test_df_transformed = race_df_transformed.loc[X_race_test_t.index].copy()\n",
    "race_test_df_transformed['prediction'] = race_test_preds_transformed\n",
    "\n",
    "original_pred_metrics = {\n",
    "    'Sex vs. Prediction': compute_manual_fairness_metrics(sex_test_df_original, 'applicant_sex', 'prediction', privileged_sex_group, unprivileged_sex_group),\n",
    "    'Race vs. Prediction': compute_manual_fairness_metrics(race_test_df_original, 'derived_race_new', 'prediction', privileged_race_group, unprivileged_race_group)\n",
    "}\n",
    "print(pd.DataFrame.from_dict(original_pred_metrics, orient='index'))\n",
    "\n",
    "\n",
    "transformed_pred_metrics = {\n",
    "    'Sex vs. Prediction': compute_manual_fairness_metrics(sex_test_df_transformed, 'applicant_sex', 'prediction', privileged_sex_group, unprivileged_sex_group),\n",
    "    'Race vs. Prediction': compute_manual_fairness_metrics(race_test_df_transformed, 'derived_race_new', 'prediction', privileged_race_group, unprivileged_race_group)\n",
    "}\n",
    "\n",
    "print(pd.DataFrame.from_dict(transformed_pred_metrics, orient='index'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324ebaef",
   "metadata": {},
   "source": [
    "## Table Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a984eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_report(protected_class_name, metric_name, original_val, transformed_val, original_pred_val, transformed_pred_val):\n",
    "    \"\"\"Creates a summary DataFrame for a given metric, matching the FAQ format.\"\"\"\n",
    "    stages = [\n",
    "        'Original Dataset', 'After Transforming Dataset', \n",
    "        'After Training Classifier on Original Dataset', \n",
    "        'After Training Classifier on Transformed Dataset'\n",
    "    ]\n",
    "    values = [original_val, transformed_val, original_pred_val, transformed_pred_val]\n",
    "    \n",
    "    report_df = pd.DataFrame({'Stage': stages, metric_name: values})\n",
    "    report_df['Change compared to previous'] = report_df[metric_name].diff()\n",
    "    \n",
    "    print(f\"\\n\\n--- Detailed Summary for: {protected_class_name} - {metric_name} ---\")\n",
    "    print(report_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2a5ffb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sex\n",
    "sex_spd_orig = original_metrics['Sex vs. Action Taken']['Statistical Parity Difference']\n",
    "sex_di_orig = original_metrics['Sex vs. Action Taken']['Disparate Impact']\n",
    "sex_spd_trans = transformed_metrics['Sex vs. Action Taken']['Statistical Parity Difference']\n",
    "sex_di_trans = transformed_metrics['Sex vs. Action Taken']['Disparate Impact']\n",
    "sex_spd_pred_orig = original_pred_metrics['Sex vs. Prediction']['Statistical Parity Difference']\n",
    "sex_di_pred_orig = original_pred_metrics['Sex vs. Prediction']['Disparate Impact']\n",
    "sex_spd_pred_trans = transformed_pred_metrics['Sex vs. Prediction']['Statistical Parity Difference']\n",
    "sex_di_pred_trans = transformed_pred_metrics['Sex vs. Prediction']['Disparate Impact']\n",
    "\n",
    "# Race\n",
    "race_spd_orig = original_metrics['Race vs. Action Taken']['Statistical Parity Difference']\n",
    "race_di_orig = original_metrics['Race vs. Action Taken']['Disparate Impact']\n",
    "race_spd_trans = transformed_metrics['Race vs. Action Taken']['Statistical Parity Difference']\n",
    "race_di_trans = transformed_metrics['Race vs. Action Taken']['Disparate Impact']\n",
    "race_spd_pred_orig = original_pred_metrics['Race vs. Prediction']['Statistical Parity Difference']\n",
    "race_di_pred_orig = original_pred_metrics['Race vs. Prediction']['Disparate Impact']\n",
    "race_spd_pred_trans = transformed_pred_metrics['Race vs. Prediction']['Statistical Parity Difference']\n",
    "race_di_pred_trans = transformed_pred_metrics['Race vs. Prediction']['Disparate Impact']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45b9e42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Detailed Summary for: Sex - Statistical Parity Difference ---\n",
      "                                           Stage  Statistical Parity Difference  Change compared to previous\n",
      "                                Original Dataset                       0.082922                          NaN\n",
      "                      After Transforming Dataset                       0.048991                    -0.033931\n",
      "   After Training Classifier on Original Dataset                       1.178995                     1.130004\n",
      "After Training Classifier on Transformed Dataset                       0.000119                    -1.178877\n",
      "\n",
      "\n",
      "--- Detailed Summary for: Sex - Disparate Impact ---\n",
      "                                           Stage  Disparate Impact  Change compared to previous\n",
      "                                Original Dataset          1.042136                          NaN\n",
      "                      After Transforming Dataset          1.024750                    -0.017386\n",
      "   After Training Classifier on Original Dataset          1.287554                     0.262803\n",
      "After Training Classifier on Transformed Dataset          1.000118                    -0.287435\n",
      "\n",
      "\n",
      "--- Detailed Summary for: Race - Statistical Parity Difference ---\n",
      "                                           Stage  Statistical Parity Difference  Change compared to previous\n",
      "                                Original Dataset                       0.367557                          NaN\n",
      "                      After Transforming Dataset                       0.201853                    -0.165703\n",
      "   After Training Classifier on Original Dataset                       0.545521                     0.343667\n",
      "After Training Classifier on Transformed Dataset                       0.000311                    -0.545210\n",
      "\n",
      "\n",
      "--- Detailed Summary for: Race - Disparate Impact ---\n",
      "                                           Stage  Disparate Impact  Change compared to previous\n",
      "                                Original Dataset          1.191670                          NaN\n",
      "                      After Transforming Dataset          1.103655                    -0.088015\n",
      "   After Training Classifier on Original Dataset          1.126932                     0.023277\n",
      "After Training Classifier on Transformed Dataset          1.000311                    -0.126621\n"
     ]
    }
   ],
   "source": [
    "# --- Generate the four required summary tables ---\n",
    "create_summary_report(\"Sex\", \"Statistical Parity Difference\", sex_spd_orig, sex_spd_trans, sex_spd_pred_orig, sex_spd_pred_trans)\n",
    "create_summary_report(\"Sex\", \"Disparate Impact\", sex_di_orig, sex_di_trans, sex_di_pred_orig, sex_di_pred_trans)\n",
    "create_summary_report(\"Race\", \"Statistical Parity Difference\", race_spd_orig, race_spd_trans, race_spd_pred_orig, race_spd_pred_trans)\n",
    "create_summary_report(\"Race\", \"Disparate Impact\", race_di_orig, race_di_trans, race_di_pred_orig, race_di_pred_trans)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
