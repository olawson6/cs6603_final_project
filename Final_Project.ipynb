{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f55da84",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db197f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915d4a9b",
   "metadata": {},
   "source": [
    "# Step 1 DataSet Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ee3eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"state_GA.csv\" \n",
    "data = pd.read_csv(file)\n",
    "\n",
    "data_reduced = data[['lei', 'derived_ethnicity', 'derived_race', 'derived_sex', 'loan_amount', 'debt_to_income_ratio', 'loan_purpose', 'loan_term', 'action_taken', 'denial_reason-1', 'denial_reason-2', \n",
    "                     'income', 'applicant_age', 'total_loan_costs', 'interest_rate', 'applicant_race-1', 'applicant_race-2', 'applicant_sex','co-applicant_sex']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5588ca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Only Need to run once\n",
    "data_reduced.to_csv(\"state_GA_reduced.csv\", index=False)\n",
    "hmda_data = pd.read_csv(\"state_GA_reduced.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55afda23",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_map = {\n",
    "    1: \"Male\",\n",
    "    2: \"Female\",\n",
    "    6: \"Applicant selected both male and female\"\n",
    "}\n",
    "\n",
    "race_map = {\n",
    "    1: \"American Indian or Alaska Native\",\n",
    "    2: \"Asian\",\n",
    "    21: \"Asian Indian\",\n",
    "    22: \"Chinese\",\n",
    "    23: \"Filipino\",\n",
    "    24: \"Japanese\",\n",
    "    25: \"Korean\",\n",
    "    26: \"Vietnamese\",\n",
    "    27: \"Other Asian\",\n",
    "    3: \"Black or African American\",\n",
    "    4: \"Native Hawaiian or Other Pacific Islander\",\n",
    "    41: \"Native Hawaiian\",\n",
    "    42: \"Guamanian or Chamorro\",\n",
    "    43: \"Samoan\",\n",
    "    44: \"Other Pacific Islander\",\n",
    "    5: \"White\"\n",
    "}\n",
    "\n",
    "data_reduced['applicant_race-1'] = pd.to_numeric(data_reduced['applicant_race-1'], errors='coerce')\n",
    "data_reduced['applicant_race-2'] = pd.to_numeric(data_reduced['applicant_race-2'], errors='coerce')\n",
    "data_reduced['applicant_sex'] = pd.to_numeric(data_reduced['applicant_sex'], errors='coerce')\n",
    "data_reduced['co-applicant_sex'] = pd.to_numeric(data_reduced['co-applicant_sex'], errors='coerce')\n",
    "\n",
    "filtered = data_reduced[\n",
    "    data_reduced['applicant_race-1'].isin(race_map.keys()) &\n",
    "    (\n",
    "        data_reduced['applicant_race-2'].isna() |\n",
    "        data_reduced['applicant_race-2'].isin(race_map.keys())\n",
    "    ) &\n",
    "    data_reduced['applicant_sex'].isin(sex_map.keys()) &\n",
    "    (\n",
    "        data_reduced['co-applicant_sex'].isna() |\n",
    "        data_reduced['co-applicant_sex'].isin(sex_map.keys())\n",
    "    )\n",
    "\n",
    "]\n",
    "\n",
    "filtered['race_1_str'] = filtered['applicant_race-1'].map(race_map)\n",
    "filtered['race_2_str'] = filtered['applicant_race-2'].map(race_map)\n",
    "def combine_races_str(row):\n",
    "    if pd.isna(row['race_2_str']) or row['race_2_str'] == \"\":\n",
    "        return row['race_1_str']\n",
    "    return f\"{row['race_1_str']}, {row['race_2_str']}\"\n",
    "def combine_sexs_str(row):\n",
    "    if pd.isna(row['co-applicant_sex']) or row['co-applicant_sex'] == \"\":\n",
    "        return row['applicant_sex']\n",
    "    return f\"{row['applicant_sex']}, {row['co-applicant_sex']}\"\n",
    "\n",
    "filtered['derived_race_new'] = filtered.apply(combine_races_str, axis=1)\n",
    "\n",
    "filtered['applicant_sex'] = filtered['applicant_sex'].map(sex_map)\n",
    "filtered['co-applicant_sex'] = filtered['co-applicant_sex'].map(sex_map)\n",
    "\n",
    "filtered['derived_sex_new'] = filtered.apply(combine_sexs_str, axis=1)\n",
    "\n",
    "filtered = filtered[filtered['action_taken'] != 6]\n",
    "filtered = filtered[filtered['interest_rate'] != 'Exempt']\n",
    "\n",
    "\n",
    "filtered['favorable_action_taken'] = filtered['action_taken'].apply(\n",
    "    lambda x: 1 if x in [1, 2, 8] else (0 if x in [3, 4, 5, 7] else pd.NA)\n",
    ")\n",
    "filtered['interest_rate'].unique()\n",
    "filtered['favorable_interest_rate'] = filtered['interest_rate'].apply(\n",
    "    lambda x: 1 if float(x) <= 7.5 else 0)\n",
    "\n",
    "unique_races = sorted(filtered['derived_race_new'].unique())\n",
    "unique_sexes = sorted(filtered['derived_sex_new'].unique())\n",
    "\n",
    "# New encoding dictionaries\n",
    "final_race_encoding = {race: i for i, race in enumerate(unique_races)}\n",
    "final_sex_encoding = {sex: i for i, sex in enumerate(unique_sexes)}\n",
    "\n",
    "filtered['derived_race_encoded'] = filtered['derived_race_new'].map(final_race_encoding)\n",
    "filtered['derived_sex_encoded'] = filtered['derived_sex_new'].map(final_sex_encoding)\n",
    "\n",
    "\n",
    "filtered.to_csv(\"state_GA_reduced_encoded.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5c15f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# top ten only\n",
    "top_10_races = filtered['derived_race_new'].value_counts().head(10).index\n",
    "filtered_race = filtered[filtered['derived_race_new'].isin(top_10_races)]\n",
    "\n",
    "tables = []\n",
    "\n",
    "for protected_var, protected_label in {\n",
    "    'derived_race_new': 'Race',\n",
    "    'derived_sex_new': 'Sex'\n",
    "}.items(): \n",
    "    subset = filtered_race if protected_var == 'derived_race_new' else filtered\n",
    "\n",
    "    for dependent_var, dependent_label in dependent_variables.items():\n",
    "        freq_table = pd.crosstab(subset[protected_var], subset[dependent_var], dropna=False)\n",
    "        freq_table.columns.name = dependent_label\n",
    "        freq_table.index.name = protected_label\n",
    "        tables.append((protected_var, dependent_var, freq_table))\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.countplot(data=subset, x=protected_var, hue=dependent_var,\n",
    "                      order=subset[protected_var].value_counts().head(10).index if protected_var == 'derived_race_new' else None)\n",
    "        plt.title(f\"{protected_label} vs {dependent_label}\")\n",
    "        plt.xlabel(protected_label)\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"charts/{protected_var}_vs_{dependent_var}.png\")\n",
    "        plt.close()\n",
    "\n",
    "for protected_var, dependent_var, table in tables:\n",
    "    print(f\"\\n===== Frequency Table: {protected_var} vs {dependent_var} =====\\n\")\n",
    "    print(table.to_latex(index=True, caption=f\"{protected_var} vs {dependent_var}\", label=f\"tab:{protected_var}_vs_{dependent_var}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49560436",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install plotly\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "bar_colors = ['#a6bddb', '#fcae91']\n",
    "pattern_shapes = ['\\\\', '/']\n",
    "\n",
    "def abbreviate_labels(labels):\n",
    "    abbr = {label: f\"{label}\" if 'both' not in label else ', '.join([i if 'both' not in i else 'both' for i in label.split(',')]) for i, label in enumerate(labels)}\n",
    "    return abbr, list(abbr.values()), abbr.items()\n",
    "\n",
    "for protected_var, protected_label in {\n",
    "    'derived_race_new': 'Race',\n",
    "    'derived_sex_new': 'Sex'\n",
    "}.items():\n",
    "    subset = filtered_race if protected_var == 'derived_race_new' else filtered\n",
    "    category_order = (\n",
    "        subset[protected_var]\n",
    "        .value_counts()\n",
    "        .head(10 if protected_var == 'derived_race_new' else None)\n",
    "        .sort_values(ascending=False)\n",
    "        .index.tolist()\n",
    "    )\n",
    "\n",
    "    abbr_map, abbr_labels, abbr_items = abbreviate_labels(category_order)\n",
    "    subset = subset[subset[protected_var].isin(category_order)].copy()\n",
    "    subset['abbr_label'] = subset[protected_var].map(abbr_map)\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        subplot_titles=[\"Favorable Interest Rate\", \"Favorable Action Taken\"],\n",
    "        horizontal_spacing=0.15\n",
    "    )\n",
    "\n",
    "    for i, dep in enumerate(['favorable_interest_rate', 'favorable_action_taken']):\n",
    "        grouped = (\n",
    "            subset\n",
    "            .groupby(['abbr_label', dep])\n",
    "            .size()\n",
    "            .reset_index(name='count')\n",
    "        )\n",
    "        for j, val in enumerate([1, 0]):\n",
    "            df = grouped[grouped[dep] == val]\n",
    "            df['abbr_label'] = pd.Categorical(df['abbr_label'], categories=abbr_labels, ordered=True)\n",
    "            df = df.sort_values('abbr_label')\n",
    "            fig.add_trace(\n",
    "                go.Bar(\n",
    "                    x=df['abbr_label'],\n",
    "                    y=df['count'],\n",
    "                    name=f\"{dep}: {val}\",\n",
    "                    marker_color=bar_colors[j],\n",
    "                    marker_pattern_shape=pattern_shapes[j],\n",
    "                    showlegend=(i == 0)\n",
    "                ),\n",
    "                row=1, col=i+1\n",
    "            )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text=f\"{protected_label} vs Favorable Outcomes\",\n",
    "        barmode='group',\n",
    "        height=700,\n",
    "        width=1000,\n",
    "        legend_title=\"Outcome Value\"\n",
    "    )\n",
    "    fig.update_xaxes(tickangle=-45)\n",
    "\n",
    "    print(f\"\\n===== Abbreviation Key for {protected_label} =====\\n\")\n",
    "    for long, short in abbr_items:\n",
    "        print(f\"{short}: {long}\")\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0d10c1",
   "metadata": {},
   "source": [
    "# Analysis for Steps 3 and 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00928235",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0972034c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('state_GA_reduced_encoded.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f27963b",
   "metadata": {},
   "source": [
    "## Data Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c92e09f",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037c6671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dropped 0 rows\n",
      "Shape: (104831, 27)\n"
     ]
    }
   ],
   "source": [
    "df['interest_rate'] = pd.to_numeric(df['interest_rate'], errors='coerce')\n",
    "df['favorable_interest_rate'] = np.where(df['interest_rate'] < 7.5, 1, 0)\n",
    "features = ['loan_amount', 'income', 'derived_race_encoded', 'derived_sex_encoded']\n",
    "\n",
    "df['income'] = pd.to_numeric(df['income'], errors='coerce')\n",
    "original_rows = len(df)\n",
    "df.dropna(subset=features, inplace=True)\n",
    "print(f\"\\nDropped {original_rows - len(df)} rows\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "\n",
    "\n",
    "sex_df = df[df['applicant_sex'].isin(['Male', 'Female'])].copy()\n",
    "race_df = df[df['derived_race_new'].isin(['White', 'Black or African American'])].copy()\n",
    "privileged_sex_group = {'applicant_sex': 'Male'}\n",
    "unprivileged_sex_group = {'applicant_sex': 'Female'}\n",
    "privileged_race_group = {'derived_race_new': 'White'}\n",
    "unprivileged_race_group = {'derived_race_new': 'Black or African American'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91dc0f0",
   "metadata": {},
   "source": [
    "# Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd225c3c",
   "metadata": {},
   "source": [
    "### Manual Fairness Metric Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4a37c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual computation of fairness metrics\n",
    "def compute_manual_fairness_metrics(df, protected_attribute, dependent_variable, privileged_group, unprivileged_group, weights_col=None):\n",
    "    priv_key, priv_val = list(privileged_group.items())[0]\n",
    "    unpriv_key, unpriv_val = list(unprivileged_group.items())[0]\n",
    "    df_priv = df[df[priv_key] == priv_val]\n",
    "    df_unpriv = df[df[unpriv_key] == unpriv_val]\n",
    "    \n",
    "    if weights_col and not df_priv.empty and not df_unpriv.empty:\n",
    "        rate_priv = (df_priv[dependent_variable] * df_priv[weights_col]).sum() / df_priv[weights_col].sum()\n",
    "        rate_unpriv = (df_unpriv[dependent_variable] * df_unpriv[weights_col]).sum() / df_unpriv[weights_col].sum()\n",
    "    elif not df_priv.empty and not df_unpriv.empty:\n",
    "        rate_priv = df_priv[dependent_variable].mean()\n",
    "        rate_unpriv = df_unpriv[dependent_variable].mean()\n",
    "    else:\n",
    "        return {'Statistical Parity Difference': np.nan, 'Disparate Impact': np.nan}\n",
    "        \n",
    "    spd = rate_unpriv - rate_priv\n",
    "    di = rate_unpriv / (rate_priv + 1e-7)\n",
    "    return {'Statistical Parity Difference': spd, 'Disparate Impact': di}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250df596",
   "metadata": {},
   "source": [
    "### Apply Reweighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "453fd575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual application of reweighting\n",
    "def apply_reweighting(df, protected_attribute, dependent_variable, privileged_group, unprivileged_group):\n",
    "    df_new = df.copy()\n",
    "    priv_key, priv_val = list(privileged_group.items())[0]\n",
    "    unpriv_key, unpriv_val = list(unprivileged_group.items())[0]\n",
    "    priv_fav = (df_new[priv_key] == priv_val) & (df_new[dependent_variable] == 1)\n",
    "    priv_unfav = (df_new[priv_key] == priv_val) & (df_new[dependent_variable] == 0)\n",
    "    unpriv_fav = (df_new[unpriv_key] == unpriv_val) & (df_new[dependent_variable] == 1)\n",
    "    unpriv_unfav = (df_new[unpriv_key] == unpriv_val) & (df_new[dependent_variable] == 0)\n",
    "    N = len(df_new)\n",
    "    p_priv = (df_new[priv_key] == priv_val).sum() / N\n",
    "    p_unpriv = (df_new[unpriv_key] == unpriv_val).sum() / N\n",
    "    p_fav = (df_new[dependent_variable] == 1).sum() / N\n",
    "    p_unfav = (df_new[dependent_variable] == 0).sum() / N\n",
    "    p_priv_fav = priv_fav.sum() / N; p_priv_unfav = priv_unfav.sum() / N\n",
    "    p_unpriv_fav = unpriv_fav.sum() / N; p_unpriv_unfav = unpriv_unfav.sum() / N\n",
    "    w_priv_fav = (p_priv * p_fav) / p_priv_fav if p_priv_fav > 0 else 1.0\n",
    "    w_priv_unfav = (p_priv * p_unfav) / p_priv_unfav if p_priv_unfav > 0 else 1.0\n",
    "    w_unpriv_fav = (p_unpriv * p_fav) / p_unpriv_fav if p_unpriv_fav > 0 else 1.0\n",
    "    w_unpriv_unfav = (p_unpriv * p_unfav) / p_unpriv_unfav if p_unpriv_unfav > 0 else 1.0\n",
    "    df_new['sample_weight'] = 1.0\n",
    "    df_new.loc[priv_fav, 'sample_weight'] = w_priv_fav\n",
    "    df_new.loc[priv_unfav, 'sample_weight'] = w_priv_unfav\n",
    "    df_new.loc[unpriv_fav, 'sample_weight'] = w_unpriv_fav\n",
    "    df_new.loc[unpriv_unfav, 'sample_weight'] = w_unpriv_unfav\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fafbafc",
   "metadata": {},
   "source": [
    "## Preprocess and Mitigate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d300f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Statistical Parity Difference  \\\n",
      "Sex vs. Action Taken                                   0.082922   \n",
      "Race vs. Action Taken                                  0.367557   \n",
      "Sex vs. Favorable Interest Rate                       -0.004527   \n",
      "Race vs. Favorable Interest Rate                      -0.073302   \n",
      "\n",
      "                                  Disparate Impact  \n",
      "Sex vs. Action Taken                      1.042136  \n",
      "Race vs. Action Taken                     1.191670  \n",
      "Sex vs. Favorable Interest Rate           0.989941  \n",
      "Race vs. Favorable Interest Rate          0.839495  \n"
     ]
    }
   ],
   "source": [
    "original_metrics = {\n",
    "    'Sex vs. Action Taken': compute_manual_fairness_metrics(sex_df, 'applicant_sex', 'action_taken', privileged_sex_group, unprivileged_sex_group),\n",
    "    'Race vs. Action Taken': compute_manual_fairness_metrics(race_df, 'derived_race_new', 'action_taken', privileged_race_group, unprivileged_race_group),\n",
    "    'Sex vs. Favorable Interest Rate': compute_manual_fairness_metrics(sex_df, 'applicant_sex', 'favorable_interest_rate', privileged_sex_group, unprivileged_sex_group),\n",
    "    'Race vs. Favorable Interest Rate': compute_manual_fairness_metrics(race_df, 'derived_race_new', 'favorable_interest_rate', privileged_race_group, unprivileged_race_group)\n",
    "}\n",
    "print(pd.DataFrame.from_dict(original_metrics, orient='index'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063234ad",
   "metadata": {},
   "source": [
    "### Reweight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00aa0895",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_df_transformed = apply_reweighting(sex_df, 'applicant_sex', 'action_taken', privileged_sex_group, unprivileged_sex_group)\n",
    "race_df_transformed = apply_reweighting(race_df, 'derived_race_new', 'action_taken', privileged_race_group, unprivileged_race_group)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68cafb7",
   "metadata": {},
   "source": [
    "### Transformed Data Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dce6794f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Statistical Parity Difference  \\\n",
      "Sex vs. Action Taken                                   0.048991   \n",
      "Race vs. Action Taken                                  0.201853   \n",
      "Sex vs. Favorable Interest Rate                        0.004373   \n",
      "Race vs. Favorable Interest Rate                      -0.028255   \n",
      "\n",
      "                                  Disparate Impact  \n",
      "Sex vs. Action Taken                      1.024750  \n",
      "Race vs. Action Taken                     1.103655  \n",
      "Sex vs. Favorable Interest Rate           1.009780  \n",
      "Race vs. Favorable Interest Rate          0.937112  \n"
     ]
    }
   ],
   "source": [
    "transformed_metrics = {\n",
    "    'Sex vs. Action Taken': compute_manual_fairness_metrics(sex_df_transformed, 'applicant_sex', 'action_taken', privileged_sex_group, unprivileged_sex_group, weights_col='sample_weight'),\n",
    "    'Race vs. Action Taken': compute_manual_fairness_metrics(race_df_transformed, 'derived_race_new', 'action_taken', privileged_race_group, unprivileged_race_group, weights_col='sample_weight'),\n",
    "    'Sex vs. Favorable Interest Rate': compute_manual_fairness_metrics(sex_df_transformed, 'applicant_sex', 'favorable_interest_rate', privileged_sex_group, unprivileged_sex_group, weights_col='sample_weight'),\n",
    "    'Race vs. Favorable Interest Rate': compute_manual_fairness_metrics(race_df_transformed, 'derived_race_new', 'favorable_interest_rate', privileged_race_group, unprivileged_race_group, weights_col='sample_weight')\n",
    "}\n",
    "print(pd.DataFrame.from_dict(transformed_metrics, orient='index'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541e1c78",
   "metadata": {},
   "source": [
    "# Step 4 Mitigating Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f897f61",
   "metadata": {},
   "source": [
    "### Data Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ced5967",
   "metadata": {},
   "source": [
    "#### Sex Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07a4e058",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sex = sex_df[features]\n",
    "y_sex = sex_df['action_taken']\n",
    "X_sex_train, X_sex_test, y_sex_train, y_sex_test = train_test_split(X_sex, y_sex, test_size=0.2, random_state=42, stratify=y_sex)\n",
    "X_sex_transformed = sex_df_transformed[features]\n",
    "y_sex_transformed = sex_df_transformed['action_taken']\n",
    "weights_sex_transformed = sex_df_transformed['sample_weight']\n",
    "X_sex_train_t, X_sex_test_t, y_sex_train_t, y_sex_test_t, w_sex_train_t, w_sex_test_t = train_test_split(\n",
    "X_sex_transformed, y_sex_transformed, weights_sex_transformed, test_size=0.2, random_state=42, stratify=y_sex_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baea033d",
   "metadata": {},
   "source": [
    "#### Race Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb8002d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_race = race_df[features]\n",
    "y_race = race_df['action_taken']\n",
    "X_race_train, X_race_test, y_race_train, y_race_test = train_test_split(X_race, y_race, test_size=0.2, random_state=42, stratify=y_race)\n",
    "X_race_transformed = race_df_transformed[features]\n",
    "y_race_transformed = race_df_transformed['action_taken']\n",
    "weights_race_transformed = race_df_transformed['sample_weight']\n",
    "X_race_train_t, X_race_test_t, y_race_train_t, y_race_test_t, w_race_train_t, w_race_test_t = train_test_split(\n",
    "X_race_transformed, y_race_transformed, weights_race_transformed, test_size=0.2, random_state=42, stratify=y_race_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c7eb63",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c26d37a",
   "metadata": {},
   "source": [
    "#### Original Data Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c48541e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of original model (Sex): 0.23\n",
      "Accuracy of original model (Race): 0.23\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "model_sex_original = LogisticRegression(random_state=42, class_weight='balanced')\n",
    "model_sex_original.fit(scaler.fit_transform(X_sex_train), y_sex_train)\n",
    "sex_test_preds_original = model_sex_original.predict(scaler.transform(X_sex_test))\n",
    "print(f\"Accuracy of original model (Sex): {accuracy_score(y_sex_test, sex_test_preds_original):.2f}\")\n",
    "\n",
    "model_race_original = LogisticRegression(random_state=42, class_weight='balanced')\n",
    "model_race_original.fit(scaler.fit_transform(X_race_train), y_race_train)\n",
    "race_test_preds_original = model_race_original.predict(scaler.transform(X_race_test))\n",
    "print(f\"Accuracy of original model (Race): {accuracy_score(y_race_test, race_test_preds_original):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f01a20b",
   "metadata": {},
   "source": [
    "#### Transformed Data Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "858a2ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of transformed model (Sex): 0.62\n",
      "Accuracy of transformed model (Race): 0.62\n"
     ]
    }
   ],
   "source": [
    "model_sex_transformed = LogisticRegression(random_state=42)\n",
    "model_sex_transformed.fit(scaler.fit_transform(X_sex_train_t), y_sex_train_t, sample_weight=w_sex_train_t)\n",
    "sex_test_preds_transformed = model_sex_transformed.predict(scaler.transform(X_sex_test_t))\n",
    "print(f\"Accuracy of transformed model (Sex): {accuracy_score(y_sex_test_t, sex_test_preds_transformed):.2f}\")\n",
    "\n",
    "\n",
    "model_race_transformed = LogisticRegression(random_state=42)\n",
    "model_race_transformed.fit(scaler.fit_transform(X_race_train_t), y_race_train_t, sample_weight=w_race_train_t)\n",
    "race_test_preds_transformed = model_race_transformed.predict(scaler.transform(X_race_test_t))\n",
    "print(f\"Accuracy of transformed model (Race): {accuracy_score(y_race_test_t, race_test_preds_transformed):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2511cada",
   "metadata": {},
   "source": [
    "## Fairness Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41b38c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Statistical Parity Difference  Disparate Impact\n",
      "Sex vs. Prediction                        1.178995          1.287554\n",
      "Race vs. Prediction                       0.545521          1.126932\n",
      "                     Statistical Parity Difference  Disparate Impact\n",
      "Sex vs. Prediction                        0.000119          1.000118\n",
      "Race vs. Prediction                       0.000311          1.000311\n"
     ]
    }
   ],
   "source": [
    "sex_test_df_original = sex_df.loc[X_sex_test.index].copy()\n",
    "sex_test_df_original['prediction'] = sex_test_preds_original\n",
    "race_test_df_original = race_df.loc[X_race_test.index].copy()\n",
    "race_test_df_original['prediction'] = race_test_preds_original\n",
    "sex_test_df_transformed = sex_df_transformed.loc[X_sex_test_t.index].copy()\n",
    "sex_test_df_transformed['prediction'] = sex_test_preds_transformed\n",
    "race_test_df_transformed = race_df_transformed.loc[X_race_test_t.index].copy()\n",
    "race_test_df_transformed['prediction'] = race_test_preds_transformed\n",
    "\n",
    "original_pred_metrics = {\n",
    "    'Sex vs. Prediction': compute_manual_fairness_metrics(sex_test_df_original, 'applicant_sex', 'prediction', privileged_sex_group, unprivileged_sex_group),\n",
    "    'Race vs. Prediction': compute_manual_fairness_metrics(race_test_df_original, 'derived_race_new', 'prediction', privileged_race_group, unprivileged_race_group)\n",
    "}\n",
    "print(pd.DataFrame.from_dict(original_pred_metrics, orient='index'))\n",
    "\n",
    "\n",
    "transformed_pred_metrics = {\n",
    "    'Sex vs. Prediction': compute_manual_fairness_metrics(sex_test_df_transformed, 'applicant_sex', 'prediction', privileged_sex_group, unprivileged_sex_group),\n",
    "    'Race vs. Prediction': compute_manual_fairness_metrics(race_test_df_transformed, 'derived_race_new', 'prediction', privileged_race_group, unprivileged_race_group)\n",
    "}\n",
    "\n",
    "print(pd.DataFrame.from_dict(transformed_pred_metrics, orient='index'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324ebaef",
   "metadata": {},
   "source": [
    "## Table Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a984eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_report(protected_class_name, metric_name, original_val, transformed_val, original_pred_val, transformed_pred_val):\n",
    "    stages = [\n",
    "        'Original Dataset', 'After Transforming Dataset', \n",
    "        'After Training Classifier on Original Dataset', \n",
    "        'After Training Classifier on Transformed Dataset'\n",
    "    ]\n",
    "    values = [original_val, transformed_val, original_pred_val, transformed_pred_val]\n",
    "    \n",
    "    report_df = pd.DataFrame({'Stage': stages, metric_name: values})\n",
    "    report_df['Change compared to previous'] = report_df[metric_name].diff()\n",
    "    \n",
    "    print(f\"\\n\\n--- Detailed Summary for: {protected_class_name} - {metric_name} ---\")\n",
    "    print(report_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2a5ffb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sex\n",
    "sex_spd_orig = original_metrics['Sex vs. Action Taken']['Statistical Parity Difference']\n",
    "sex_di_orig = original_metrics['Sex vs. Action Taken']['Disparate Impact']\n",
    "sex_spd_trans = transformed_metrics['Sex vs. Action Taken']['Statistical Parity Difference']\n",
    "sex_di_trans = transformed_metrics['Sex vs. Action Taken']['Disparate Impact']\n",
    "sex_spd_pred_orig = original_pred_metrics['Sex vs. Prediction']['Statistical Parity Difference']\n",
    "sex_di_pred_orig = original_pred_metrics['Sex vs. Prediction']['Disparate Impact']\n",
    "sex_spd_pred_trans = transformed_pred_metrics['Sex vs. Prediction']['Statistical Parity Difference']\n",
    "sex_di_pred_trans = transformed_pred_metrics['Sex vs. Prediction']['Disparate Impact']\n",
    "\n",
    "# Race\n",
    "race_spd_orig = original_metrics['Race vs. Action Taken']['Statistical Parity Difference']\n",
    "race_di_orig = original_metrics['Race vs. Action Taken']['Disparate Impact']\n",
    "race_spd_trans = transformed_metrics['Race vs. Action Taken']['Statistical Parity Difference']\n",
    "race_di_trans = transformed_metrics['Race vs. Action Taken']['Disparate Impact']\n",
    "race_spd_pred_orig = original_pred_metrics['Race vs. Prediction']['Statistical Parity Difference']\n",
    "race_di_pred_orig = original_pred_metrics['Race vs. Prediction']['Disparate Impact']\n",
    "race_spd_pred_trans = transformed_pred_metrics['Race vs. Prediction']['Statistical Parity Difference']\n",
    "race_di_pred_trans = transformed_pred_metrics['Race vs. Prediction']['Disparate Impact']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45b9e42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Detailed Summary for: Sex - Statistical Parity Difference ---\n",
      "                                           Stage  Statistical Parity Difference  Change compared to previous\n",
      "                                Original Dataset                       0.082922                          NaN\n",
      "                      After Transforming Dataset                       0.048991                    -0.033931\n",
      "   After Training Classifier on Original Dataset                       1.178995                     1.130004\n",
      "After Training Classifier on Transformed Dataset                       0.000119                    -1.178877\n",
      "\n",
      "\n",
      "--- Detailed Summary for: Sex - Disparate Impact ---\n",
      "                                           Stage  Disparate Impact  Change compared to previous\n",
      "                                Original Dataset          1.042136                          NaN\n",
      "                      After Transforming Dataset          1.024750                    -0.017386\n",
      "   After Training Classifier on Original Dataset          1.287554                     0.262803\n",
      "After Training Classifier on Transformed Dataset          1.000118                    -0.287435\n",
      "\n",
      "\n",
      "--- Detailed Summary for: Race - Statistical Parity Difference ---\n",
      "                                           Stage  Statistical Parity Difference  Change compared to previous\n",
      "                                Original Dataset                       0.367557                          NaN\n",
      "                      After Transforming Dataset                       0.201853                    -0.165703\n",
      "   After Training Classifier on Original Dataset                       0.545521                     0.343667\n",
      "After Training Classifier on Transformed Dataset                       0.000311                    -0.545210\n",
      "\n",
      "\n",
      "--- Detailed Summary for: Race - Disparate Impact ---\n",
      "                                           Stage  Disparate Impact  Change compared to previous\n",
      "                                Original Dataset          1.191670                          NaN\n",
      "                      After Transforming Dataset          1.103655                    -0.088015\n",
      "   After Training Classifier on Original Dataset          1.126932                     0.023277\n",
      "After Training Classifier on Transformed Dataset          1.000311                    -0.126621\n"
     ]
    }
   ],
   "source": [
    "create_summary_report(\"Sex\", \"Statistical Parity Difference\", sex_spd_orig, sex_spd_trans, sex_spd_pred_orig, sex_spd_pred_trans)\n",
    "create_summary_report(\"Sex\", \"Disparate Impact\", sex_di_orig, sex_di_trans, sex_di_pred_orig, sex_di_pred_trans)\n",
    "create_summary_report(\"Race\", \"Statistical Parity Difference\", race_spd_orig, race_spd_trans, race_spd_pred_orig, race_spd_pred_trans)\n",
    "create_summary_report(\"Race\", \"Disparate Impact\", race_di_orig, race_di_trans, race_di_pred_orig, race_di_pred_trans)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
