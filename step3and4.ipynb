{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-20T20:34:07.533665Z",
     "start_time": "2025-07-20T20:34:07.529899Z"
    }
   },
   "source": [
    ""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T20:34:09.332148Z",
     "start_time": "2025-07-20T20:34:07.546437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ==============================================================================\n",
    "# STEP 3: FAIRNESS METRICS & PRE-PROCESSING MITIGATION\n",
    "# ==============================================================================\n",
    "print(\"--- Running Step 3: Dataset Analysis and Manual Reweighting ---\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3.1: DATA LOADING AND PREPARATION\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n[Step 3.1] Loading and Preparing Data...\")\n",
    "\n",
    "# Load data\n",
    "try:\n",
    "    df = pd.read_csv('state_GA_reduced_encoded.csv')\n",
    "    print(\"Dataset loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'state_GA_reduced_encoded.csv' not found.\")\n",
    "    exit()\n",
    "\n",
    "# --- Initial Data Exploration ---\n",
    "print(\"\\n--- Initial Data Summary ---\")\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "print(\"\\nData Info:\")\n",
    "df.info()\n",
    "print(\"\\nValue Counts for Action Taken:\")\n",
    "print(df['action_taken'].value_counts())\n",
    "\n",
    "\n",
    "# Clean interest rate and create dependent variables\n",
    "df['interest_rate'] = pd.to_numeric(df['interest_rate'], errors='coerce')\n",
    "df['favorable_interest_rate'] = np.where(df['interest_rate'] < 7.5, 1, 0)\n",
    "print(\"\\nDependent variables prepared.\")\n",
    "\n",
    "# Define features that will be used in the model.\n",
    "FEATURES = ['loan_amount', 'income', 'derived_race_encoded', 'derived_sex_encoded']\n",
    "\n",
    "# Convert feature columns to numeric and drop rows with missing values IN THOSE COLUMNS.\n",
    "df['income'] = pd.to_numeric(df['income'], errors='coerce')\n",
    "original_rows = len(df)\n",
    "df.dropna(subset=FEATURES, inplace=True)\n",
    "print(f\"\\nDropped {original_rows - len(df)} rows with missing values in feature columns to prepare for modeling.\")\n",
    "print(f\"Shape of data ready for modeling: {df.shape}\")\n",
    "\n",
    "\n",
    "# Filter for protected class analysis and define groups\n",
    "sex_df = df[df['applicant_sex'].isin(['Male', 'Female'])].copy()\n",
    "race_df = df[df['derived_race_new'].isin(['White', 'Black or African American'])].copy()\n",
    "privileged_sex_group = {'applicant_sex': 'Male'}\n",
    "unprivileged_sex_group = {'applicant_sex': 'Female'}\n",
    "privileged_race_group = {'derived_race_new': 'White'}\n",
    "unprivileged_race_group = {'derived_race_new': 'Black or African American'}\n",
    "print(\"\\n--- Protected Class Subgroup Counts ---\")\n",
    "print(\"\\nSex Analysis Subgroups (sex_df):\")\n",
    "print(sex_df['applicant_sex'].value_counts())\n",
    "print(\"\\nRace Analysis Subgroups (race_df):\")\n",
    "print(race_df['derived_race_new'].value_counts())\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3.2: MANUAL HELPER FUNCTIONS (METRICS AND REWEIGHTING)\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def compute_manual_fairness_metrics(df, protected_attribute, dependent_variable, privileged_group, unprivileged_group, weights_col=None):\n",
    "    \"\"\"Computes SPD and DI manually, with optional sample weights.\"\"\"\n",
    "    priv_key, priv_val = list(privileged_group.items())[0]\n",
    "    unpriv_key, unpriv_val = list(unprivileged_group.items())[0]\n",
    "    df_priv = df[df[priv_key] == priv_val]\n",
    "    df_unpriv = df[df[unpriv_key] == unpriv_val]\n",
    "    \n",
    "    if weights_col and not df_priv.empty and not df_unpriv.empty:\n",
    "        rate_priv = (df_priv[dependent_variable] * df_priv[weights_col]).sum() / df_priv[weights_col].sum()\n",
    "        rate_unpriv = (df_unpriv[dependent_variable] * df_unpriv[weights_col]).sum() / df_unpriv[weights_col].sum()\n",
    "    elif not df_priv.empty and not df_unpriv.empty:\n",
    "        rate_priv = df_priv[dependent_variable].mean()\n",
    "        rate_unpriv = df_unpriv[dependent_variable].mean()\n",
    "    else:\n",
    "        return {'Statistical Parity Difference': np.nan, 'Disparate Impact': np.nan}\n",
    "        \n",
    "    spd = rate_unpriv - rate_priv\n",
    "    di = rate_unpriv / (rate_priv + 1e-7)\n",
    "    return {'Statistical Parity Difference': spd, 'Disparate Impact': di}\n",
    "\n",
    "def apply_reweighting(df, protected_attribute, dependent_variable, privileged_group, unprivileged_group):\n",
    "    \"\"\"Applies the Reweighting algorithm manually.\"\"\"\n",
    "    df_new = df.copy()\n",
    "    priv_key, priv_val = list(privileged_group.items())[0]\n",
    "    unpriv_key, unpriv_val = list(unprivileged_group.items())[0]\n",
    "    priv_fav = (df_new[priv_key] == priv_val) & (df_new[dependent_variable] == 1)\n",
    "    priv_unfav = (df_new[priv_key] == priv_val) & (df_new[dependent_variable] == 0)\n",
    "    unpriv_fav = (df_new[unpriv_key] == unpriv_val) & (df_new[dependent_variable] == 1)\n",
    "    unpriv_unfav = (df_new[unpriv_key] == unpriv_val) & (df_new[dependent_variable] == 0)\n",
    "    N = len(df_new)\n",
    "    p_priv = (df_new[priv_key] == priv_val).sum() / N\n",
    "    p_unpriv = (df_new[unpriv_key] == unpriv_val).sum() / N\n",
    "    p_fav = (df_new[dependent_variable] == 1).sum() / N\n",
    "    p_unfav = (df_new[dependent_variable] == 0).sum() / N\n",
    "    p_priv_fav = priv_fav.sum() / N; p_priv_unfav = priv_unfav.sum() / N\n",
    "    p_unpriv_fav = unpriv_fav.sum() / N; p_unpriv_unfav = unpriv_unfav.sum() / N\n",
    "    w_priv_fav = (p_priv * p_fav) / p_priv_fav if p_priv_fav > 0 else 1.0\n",
    "    w_priv_unfav = (p_priv * p_unfav) / p_priv_unfav if p_priv_unfav > 0 else 1.0\n",
    "    w_unpriv_fav = (p_unpriv * p_fav) / p_unpriv_fav if p_unpriv_fav > 0 else 1.0\n",
    "    w_unpriv_unfav = (p_unpriv * p_unfav) / p_unpriv_unfav if p_unpriv_unfav > 0 else 1.0\n",
    "    df_new['sample_weight'] = 1.0\n",
    "    df_new.loc[priv_fav, 'sample_weight'] = w_priv_fav\n",
    "    df_new.loc[priv_unfav, 'sample_weight'] = w_priv_unfav\n",
    "    df_new.loc[unpriv_fav, 'sample_weight'] = w_unpriv_fav\n",
    "    df_new.loc[unpriv_unfav, 'sample_weight'] = w_unpriv_unfav\n",
    "    return df_new\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3.3 & 3.4: APPLY MITIGATION AND CALCULATE METRICS\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n[Step 3.2-3.4] Calculating initial metrics and applying reweighting...\")\n",
    "\n",
    "# --- Calculate Metrics on Original Data ---\n",
    "original_metrics = {\n",
    "    'Sex vs. Action Taken': compute_manual_fairness_metrics(sex_df, 'applicant_sex', 'action_taken', privileged_sex_group, unprivileged_sex_group),\n",
    "    'Race vs. Action Taken': compute_manual_fairness_metrics(race_df, 'derived_race_new', 'action_taken', privileged_race_group, unprivileged_race_group),\n",
    "    'Sex vs. Favorable Interest Rate': compute_manual_fairness_metrics(sex_df, 'applicant_sex', 'favorable_interest_rate', privileged_sex_group, unprivileged_sex_group),\n",
    "    'Race vs. Favorable Interest Rate': compute_manual_fairness_metrics(race_df, 'derived_race_new', 'favorable_interest_rate', privileged_race_group, unprivileged_race_group)\n",
    "}\n",
    "print(\"\\n--- Step 3.2: Fairness Metrics on Original Dataset ---\")\n",
    "print(pd.DataFrame.from_dict(original_metrics, orient='index'))\n",
    "\n",
    "\n",
    "# --- Apply Reweighting and Get Transformed DataFrames ---\n",
    "sex_df_transformed = apply_reweighting(sex_df, 'applicant_sex', 'action_taken', privileged_sex_group, unprivileged_sex_group)\n",
    "race_df_transformed = apply_reweighting(race_df, 'derived_race_new', 'action_taken', privileged_race_group, unprivileged_race_group)\n",
    "print(\"\\nReweighting applied to create transformed datasets.\")\n",
    "\n",
    "# --- Calculate Metrics on Transformed Data ---\n",
    "transformed_metrics = {\n",
    "    'Sex vs. Action Taken': compute_manual_fairness_metrics(sex_df_transformed, 'applicant_sex', 'action_taken', privileged_sex_group, unprivileged_sex_group, weights_col='sample_weight'),\n",
    "    'Race vs. Action Taken': compute_manual_fairness_metrics(race_df_transformed, 'derived_race_new', 'action_taken', privileged_race_group, unprivileged_race_group, weights_col='sample_weight'),\n",
    "    'Sex vs. Favorable Interest Rate': compute_manual_fairness_metrics(sex_df_transformed, 'applicant_sex', 'favorable_interest_rate', privileged_sex_group, unprivileged_sex_group, weights_col='sample_weight'),\n",
    "    'Race vs. Favorable Interest Rate': compute_manual_fairness_metrics(race_df_transformed, 'derived_race_new', 'favorable_interest_rate', privileged_race_group, unprivileged_race_group, weights_col='sample_weight')\n",
    "}\n",
    "print(\"\\n--- Step 3.4: Fairness Metrics on Transformed (Reweighted) Dataset ---\")\n",
    "print(pd.DataFrame.from_dict(transformed_metrics, orient='index'))\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# STEP 4: MITIGATING BIAS IN A CLASSIFIER\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Running Step 4: Training and Evaluating Classifiers ---\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 4.1: DATA SPLITTING\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n[Step 4.1] Splitting data...\")\n",
    "\n",
    "# --- For Sex Analysis ---\n",
    "X_sex = sex_df[FEATURES]\n",
    "y_sex = sex_df['action_taken']\n",
    "X_sex_train, X_sex_test, y_sex_train, y_sex_test = train_test_split(X_sex, y_sex, test_size=0.2, random_state=42, stratify=y_sex)\n",
    "X_sex_transformed = sex_df_transformed[FEATURES]\n",
    "y_sex_transformed = sex_df_transformed['action_taken']\n",
    "weights_sex_transformed = sex_df_transformed['sample_weight']\n",
    "X_sex_train_t, X_sex_test_t, y_sex_train_t, y_sex_test_t, w_sex_train_t, w_sex_test_t = train_test_split(\n",
    "    X_sex_transformed, y_sex_transformed, weights_sex_transformed, test_size=0.2, random_state=42, stratify=y_sex_transformed)\n",
    "\n",
    "# --- For Race Analysis ---\n",
    "X_race = race_df[FEATURES]\n",
    "y_race = race_df['action_taken']\n",
    "X_race_train, X_race_test, y_race_train, y_race_test = train_test_split(X_race, y_race, test_size=0.2, random_state=42, stratify=y_race)\n",
    "X_race_transformed = race_df_transformed[FEATURES]\n",
    "y_race_transformed = race_df_transformed['action_taken']\n",
    "weights_race_transformed = race_df_transformed['sample_weight']\n",
    "X_race_train_t, X_race_test_t, y_race_train_t, y_race_test_t, w_race_train_t, w_race_test_t = train_test_split(\n",
    "    X_race_transformed, y_race_transformed, weights_race_transformed, test_size=0.2, random_state=42, stratify=y_race_transformed)\n",
    "print(\"Data splitting complete.\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 4.2: MODEL TRAINING AND PREDICTION\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n[Step 4.2] Training models and making predictions...\")\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# --- Original Data Models ---\n",
    "model_sex_original = LogisticRegression(random_state=42, class_weight='balanced')\n",
    "model_sex_original.fit(scaler.fit_transform(X_sex_train), y_sex_train)\n",
    "sex_test_preds_original = model_sex_original.predict(scaler.transform(X_sex_test))\n",
    "print(f\"Accuracy of original model (Sex): {accuracy_score(y_sex_test, sex_test_preds_original):.2f}\")\n",
    "\n",
    "model_race_original = LogisticRegression(random_state=42, class_weight='balanced')\n",
    "model_race_original.fit(scaler.fit_transform(X_race_train), y_race_train)\n",
    "race_test_preds_original = model_race_original.predict(scaler.transform(X_race_test))\n",
    "print(f\"Accuracy of original model (Race): {accuracy_score(y_race_test, race_test_preds_original):.2f}\")\n",
    "\n",
    "\n",
    "# --- Transformed Data Models ---\n",
    "model_sex_transformed = LogisticRegression(random_state=42)\n",
    "model_sex_transformed.fit(scaler.fit_transform(X_sex_train_t), y_sex_train_t, sample_weight=w_sex_train_t)\n",
    "sex_test_preds_transformed = model_sex_transformed.predict(scaler.transform(X_sex_test_t))\n",
    "print(f\"Accuracy of transformed model (Sex): {accuracy_score(y_sex_test_t, sex_test_preds_transformed):.2f}\")\n",
    "\n",
    "\n",
    "model_race_transformed = LogisticRegression(random_state=42)\n",
    "model_race_transformed.fit(scaler.fit_transform(X_race_train_t), y_race_train_t, sample_weight=w_race_train_t)\n",
    "race_test_preds_transformed = model_race_transformed.predict(scaler.transform(X_race_test_t))\n",
    "print(f\"Accuracy of transformed model (Race): {accuracy_score(y_race_test_t, race_test_preds_transformed):.2f}\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 4.3: CALCULATE FAIRNESS METRICS ON PREDICTIONS\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n[Step 4.3] Calculating fairness metrics on model predictions...\")\n",
    "sex_test_df_original = sex_df.loc[X_sex_test.index].copy()\n",
    "sex_test_df_original['prediction'] = sex_test_preds_original\n",
    "race_test_df_original = race_df.loc[X_race_test.index].copy()\n",
    "race_test_df_original['prediction'] = race_test_preds_original\n",
    "sex_test_df_transformed = sex_df_transformed.loc[X_sex_test_t.index].copy()\n",
    "sex_test_df_transformed['prediction'] = sex_test_preds_transformed\n",
    "race_test_df_transformed = race_df_transformed.loc[X_race_test_t.index].copy()\n",
    "race_test_df_transformed['prediction'] = race_test_preds_transformed\n",
    "\n",
    "original_pred_metrics = {\n",
    "    'Sex vs. Prediction': compute_manual_fairness_metrics(sex_test_df_original, 'applicant_sex', 'prediction', privileged_sex_group, unprivileged_sex_group),\n",
    "    'Race vs. Prediction': compute_manual_fairness_metrics(race_test_df_original, 'derived_race_new', 'prediction', privileged_race_group, unprivileged_race_group)\n",
    "}\n",
    "print(\"\\n--- Step 4.3: Fairness Metrics on Original Model's Predictions ---\")\n",
    "print(pd.DataFrame.from_dict(original_pred_metrics, orient='index'))\n",
    "\n",
    "\n",
    "transformed_pred_metrics = {\n",
    "    'Sex vs. Prediction': compute_manual_fairness_metrics(sex_test_df_transformed, 'applicant_sex', 'prediction', privileged_sex_group, unprivileged_sex_group),\n",
    "    'Race vs. Prediction': compute_manual_fairness_metrics(race_test_df_transformed, 'derived_race_new', 'prediction', privileged_race_group, unprivileged_race_group)\n",
    "}\n",
    "print(\"\\n--- Step 4.6: Fairness Metrics on Transformed Model's Predictions ---\")\n",
    "print(pd.DataFrame.from_dict(transformed_pred_metrics, orient='index'))\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 4.4: FINAL REPORTING TABLES (AS PER FAQ)\n",
    "# ------------------------------------------------------------------------------\n",
    "def create_summary_report(protected_class_name, metric_name, original_val, transformed_val, original_pred_val, transformed_pred_val):\n",
    "    \"\"\"Creates a summary DataFrame for a given metric, matching the FAQ format.\"\"\"\n",
    "    stages = [\n",
    "        'Original Dataset', 'After Transforming Dataset', \n",
    "        'After Training Classifier on Original Dataset', \n",
    "        'After Training Classifier on Transformed Dataset'\n",
    "    ]\n",
    "    values = [original_val, transformed_val, original_pred_val, transformed_pred_val]\n",
    "    \n",
    "    report_df = pd.DataFrame({'Stage': stages, metric_name: values})\n",
    "    report_df['Change compared to previous'] = report_df[metric_name].diff()\n",
    "    \n",
    "    print(f\"\\n\\n--- Detailed Summary for: {protected_class_name} - {metric_name} ---\")\n",
    "    print(report_df.to_string(index=False))\n",
    "\n",
    "# --- Gather all metric values ---\n",
    "# Sex\n",
    "sex_spd_orig = original_metrics['Sex vs. Action Taken']['Statistical Parity Difference']\n",
    "sex_di_orig = original_metrics['Sex vs. Action Taken']['Disparate Impact']\n",
    "sex_spd_trans = transformed_metrics['Sex vs. Action Taken']['Statistical Parity Difference']\n",
    "sex_di_trans = transformed_metrics['Sex vs. Action Taken']['Disparate Impact']\n",
    "sex_spd_pred_orig = original_pred_metrics['Sex vs. Prediction']['Statistical Parity Difference']\n",
    "sex_di_pred_orig = original_pred_metrics['Sex vs. Prediction']['Disparate Impact']\n",
    "sex_spd_pred_trans = transformed_pred_metrics['Sex vs. Prediction']['Statistical Parity Difference']\n",
    "sex_di_pred_trans = transformed_pred_metrics['Sex vs. Prediction']['Disparate Impact']\n",
    "\n",
    "# Race\n",
    "race_spd_orig = original_metrics['Race vs. Action Taken']['Statistical Parity Difference']\n",
    "race_di_orig = original_metrics['Race vs. Action Taken']['Disparate Impact']\n",
    "race_spd_trans = transformed_metrics['Race vs. Action Taken']['Statistical Parity Difference']\n",
    "race_di_trans = transformed_metrics['Race vs. Action Taken']['Disparate Impact']\n",
    "race_spd_pred_orig = original_pred_metrics['Race vs. Prediction']['Statistical Parity Difference']\n",
    "race_di_pred_orig = original_pred_metrics['Race vs. Prediction']['Disparate Impact']\n",
    "race_spd_pred_trans = transformed_pred_metrics['Race vs. Prediction']['Statistical Parity Difference']\n",
    "race_di_pred_trans = transformed_pred_metrics['Race vs. Prediction']['Disparate Impact']\n",
    "\n",
    "# --- Generate the four required summary tables ---\n",
    "create_summary_report(\"Sex\", \"Statistical Parity Difference\", sex_spd_orig, sex_spd_trans, sex_spd_pred_orig, sex_spd_pred_trans)\n",
    "create_summary_report(\"Sex\", \"Disparate Impact\", sex_di_orig, sex_di_trans, sex_di_pred_orig, sex_di_pred_trans)\n",
    "create_summary_report(\"Race\", \"Statistical Parity Difference\", race_spd_orig, race_spd_trans, race_spd_pred_orig, race_spd_pred_trans)\n",
    "create_summary_report(\"Race\", \"Disparate Impact\", race_di_orig, race_di_trans, race_di_pred_orig, race_di_pred_trans)\n",
    "\n"
   ],
   "id": "a7b839f037ee6cf5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Step 3: Dataset Analysis and Manual Reweighting ---\n",
      "\n",
      "[Step 3.1] Loading and Preparing Data...\n",
      "Dataset loaded successfully.\n",
      "\n",
      "--- Initial Data Summary ---\n",
      "Original dataset shape: (109250, 26)\n",
      "\n",
      "Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 109250 entries, 0 to 109249\n",
      "Data columns (total 26 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   lei                   109250 non-null  object \n",
      " 1   derived_ethnicity     109250 non-null  object \n",
      " 2   derived_race          109250 non-null  object \n",
      " 3   derived_sex           109250 non-null  object \n",
      " 4   loan_amount           109250 non-null  float64\n",
      " 5   debt_to_income_ratio  84112 non-null   object \n",
      " 6   loan_purpose          109250 non-null  int64  \n",
      " 7   loan_term             108220 non-null  object \n",
      " 8   action_taken          109250 non-null  int64  \n",
      " 9   denial_reason-1       109250 non-null  int64  \n",
      " 10  denial_reason-2       3930 non-null    float64\n",
      " 11  income                104831 non-null  float64\n",
      " 12  applicant_age         109250 non-null  object \n",
      " 13  total_loan_costs      54646 non-null   object \n",
      " 14  interest_rate         69954 non-null   object \n",
      " 15  applicant_race-1      109250 non-null  float64\n",
      " 16  applicant_race-2      6721 non-null    float64\n",
      " 17  applicant_sex         109250 non-null  object \n",
      " 18  co-applicant_sex      109250 non-null  object \n",
      " 19  race_1_str            109250 non-null  object \n",
      " 20  race_2_str            6721 non-null    object \n",
      " 21  derived_race_new      109250 non-null  object \n",
      " 22  derived_sex_new       109250 non-null  object \n",
      " 23  derived_action_taken  109250 non-null  int64  \n",
      " 24  derived_race_encoded  109250 non-null  int64  \n",
      " 25  derived_sex_encoded   109250 non-null  int64  \n",
      "dtypes: float64(5), int64(6), object(15)\n",
      "memory usage: 21.7+ MB\n",
      "\n",
      "Value Counts for Action Taken:\n",
      "action_taken\n",
      "1    66911\n",
      "3    17876\n",
      "4    15723\n",
      "5     5695\n",
      "2     2842\n",
      "8      144\n",
      "7       59\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Dependent variables prepared.\n",
      "\n",
      "Dropped 4419 rows with missing values in feature columns to prepare for modeling.\n",
      "Shape of data ready for modeling: (104831, 27)\n",
      "\n",
      "--- Protected Class Subgroup Counts ---\n",
      "\n",
      "Sex Analysis Subgroups (sex_df):\n",
      "applicant_sex\n",
      "Male      68120\n",
      "Female    36442\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Race Analysis Subgroups (race_df):\n",
      "derived_race_new\n",
      "White                        75422\n",
      "Black or African American    19982\n",
      "Name: count, dtype: int64\n",
      "\n",
      "[Step 3.2-3.4] Calculating initial metrics and applying reweighting...\n",
      "\n",
      "--- Step 3.2: Fairness Metrics on Original Dataset ---\n",
      "                                  Statistical Parity Difference  \\\n",
      "Sex vs. Action Taken                                   0.082922   \n",
      "Race vs. Action Taken                                  0.367557   \n",
      "Sex vs. Favorable Interest Rate                       -0.004527   \n",
      "Race vs. Favorable Interest Rate                      -0.073302   \n",
      "\n",
      "                                  Disparate Impact  \n",
      "Sex vs. Action Taken                      1.042136  \n",
      "Race vs. Action Taken                     1.191670  \n",
      "Sex vs. Favorable Interest Rate           0.989941  \n",
      "Race vs. Favorable Interest Rate          0.839495  \n",
      "\n",
      "Reweighting applied to create transformed datasets.\n",
      "\n",
      "--- Step 3.4: Fairness Metrics on Transformed (Reweighted) Dataset ---\n",
      "                                  Statistical Parity Difference  \\\n",
      "Sex vs. Action Taken                                   0.048991   \n",
      "Race vs. Action Taken                                  0.201853   \n",
      "Sex vs. Favorable Interest Rate                        0.004373   \n",
      "Race vs. Favorable Interest Rate                      -0.028255   \n",
      "\n",
      "                                  Disparate Impact  \n",
      "Sex vs. Action Taken                      1.024750  \n",
      "Race vs. Action Taken                     1.103655  \n",
      "Sex vs. Favorable Interest Rate           1.009780  \n",
      "Race vs. Favorable Interest Rate          0.937112  \n",
      "\n",
      "--- Running Step 4: Training and Evaluating Classifiers ---\n",
      "\n",
      "[Step 4.1] Splitting data...\n",
      "Data splitting complete.\n",
      "\n",
      "[Step 4.2] Training models and making predictions...\n",
      "Accuracy of original model (Sex): 0.23\n",
      "Accuracy of original model (Race): 0.23\n",
      "Accuracy of transformed model (Sex): 0.62\n",
      "Accuracy of transformed model (Race): 0.62\n",
      "\n",
      "[Step 4.3] Calculating fairness metrics on model predictions...\n",
      "\n",
      "--- Step 4.3: Fairness Metrics on Original Model's Predictions ---\n",
      "                     Statistical Parity Difference  Disparate Impact\n",
      "Sex vs. Prediction                        1.178995          1.287554\n",
      "Race vs. Prediction                       0.545521          1.126932\n",
      "\n",
      "--- Step 4.6: Fairness Metrics on Transformed Model's Predictions ---\n",
      "                     Statistical Parity Difference  Disparate Impact\n",
      "Sex vs. Prediction                        0.000119          1.000118\n",
      "Race vs. Prediction                       0.000311          1.000311\n",
      "\n",
      "\n",
      "--- Detailed Summary for: Sex - Statistical Parity Difference ---\n",
      "                                           Stage  Statistical Parity Difference  Change compared to previous\n",
      "                                Original Dataset                       0.082922                          NaN\n",
      "                      After Transforming Dataset                       0.048991                    -0.033931\n",
      "   After Training Classifier on Original Dataset                       1.178995                     1.130004\n",
      "After Training Classifier on Transformed Dataset                       0.000119                    -1.178877\n",
      "\n",
      "\n",
      "--- Detailed Summary for: Sex - Disparate Impact ---\n",
      "                                           Stage  Disparate Impact  Change compared to previous\n",
      "                                Original Dataset          1.042136                          NaN\n",
      "                      After Transforming Dataset          1.024750                    -0.017386\n",
      "   After Training Classifier on Original Dataset          1.287554                     0.262803\n",
      "After Training Classifier on Transformed Dataset          1.000118                    -0.287435\n",
      "\n",
      "\n",
      "--- Detailed Summary for: Race - Statistical Parity Difference ---\n",
      "                                           Stage  Statistical Parity Difference  Change compared to previous\n",
      "                                Original Dataset                       0.367557                          NaN\n",
      "                      After Transforming Dataset                       0.201853                    -0.165703\n",
      "   After Training Classifier on Original Dataset                       0.545521                     0.343667\n",
      "After Training Classifier on Transformed Dataset                       0.000311                    -0.545210\n",
      "\n",
      "\n",
      "--- Detailed Summary for: Race - Disparate Impact ---\n",
      "                                           Stage  Disparate Impact  Change compared to previous\n",
      "                                Original Dataset          1.191670                          NaN\n",
      "                      After Transforming Dataset          1.103655                    -0.088015\n",
      "   After Training Classifier on Original Dataset          1.126932                     0.023277\n",
      "After Training Classifier on Transformed Dataset          1.000311                    -0.126621\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
